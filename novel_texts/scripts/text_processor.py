#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´æ–‡æœ¬å¤„ç†å™¨ - å°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
è§£å†³ç¡¬ç¼–ç é—®é¢˜ï¼Œå®ç°æ•°æ®é©±åŠ¨çš„å†…å®¹ç®¡ç†
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Tuple

class NovelTextProcessor:
    """å°è¯´æ–‡æœ¬å¤„ç†å™¨"""
    
    def __init__(self):
        self.chapters = {}
        self.scenes = {}
        self.choices = {}
    
    def process_raw_text(self, text_file: str) -> Dict:
        """å¤„ç†åŸå§‹å°è¯´æ–‡æœ¬"""
        print(f"ğŸ“– å¼€å§‹å¤„ç†åŸå§‹æ–‡æœ¬: {text_file}")
        
        with open(text_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰ç« èŠ‚åˆ†å‰²
        chapters = self.split_by_chapters(content)
        
        # æŒ‰åœºæ™¯åˆ†å‰²
        for chapter_num, chapter_content in chapters.items():
            scenes = self.split_by_scenes(chapter_content)
            self.chapters[chapter_num] = scenes
        
        return self.chapters
    
    def split_by_chapters(self, content: str) -> Dict[int, str]:
        """æŒ‰ç« èŠ‚åˆ†å‰²æ–‡æœ¬"""
        chapters = {}
        
        # åŒ¹é…ç« èŠ‚æ ‡é¢˜çš„æ­£åˆ™è¡¨è¾¾å¼
        chapter_pattern = r'ç¬¬(\d+)ç« [^\n]*\n'
        
        # æ‰¾åˆ°æ‰€æœ‰ç« èŠ‚ä½ç½®
        chapter_matches = list(re.finditer(chapter_pattern, content))
        
        for i, match in enumerate(chapter_matches):
            chapter_num = int(match.group(1))
            start_pos = match.end()
            
            # ç¡®å®šç« èŠ‚ç»“æŸä½ç½®
            if i + 1 < len(chapter_matches):
                end_pos = chapter_matches[i + 1].start()
            else:
                end_pos = len(content)
            
            chapter_content = content[start_pos:end_pos].strip()
            chapters[chapter_num] = chapter_content
            
        print(f"âœ… åˆ†å‰²å‡º {len(chapters)} ä¸ªç« èŠ‚")
        return chapters
    
    def split_by_scenes(self, chapter_content: str) -> List[Dict]:
        """æŒ‰åœºæ™¯åˆ†å‰²ç« èŠ‚å†…å®¹"""
        scenes = []
        
        # æŒ‰æ®µè½åˆ†å‰²ï¼Œæ¯ä¸ªæ®µè½ä½œä¸ºä¸€ä¸ªåœºæ™¯
        paragraphs = [p.strip() for p in chapter_content.split('\n\n') if p.strip()]
        
        # åˆå¹¶çŸ­æ®µè½ï¼Œé¿å…åœºæ™¯è¿‡äºç¢ç‰‡åŒ–
        merged_scenes = self.merge_short_paragraphs(paragraphs)
        
        for i, scene_content in enumerate(merged_scenes, 1):
            scene = {
                'scene_id': i,
                'title': self.generate_scene_title(scene_content, i),
                'content': scene_content,
                'type': self.determine_scene_type(scene_content),
                'is_ending': self.is_ending_scene(scene_content)
            }
            scenes.append(scene)
        
        return scenes
    
    def merge_short_paragraphs(self, paragraphs: List[str], min_length: int = 100) -> List[str]:
        """åˆå¹¶è¿‡çŸ­çš„æ®µè½"""
        merged = []
        current_scene = ""
        
        for paragraph in paragraphs:
            current_scene += paragraph + "\n\n"
            
            # å¦‚æœå½“å‰åœºæ™¯è¶³å¤Ÿé•¿ï¼Œæˆ–è€…æ˜¯å¯¹è¯åœºæ™¯ï¼Œå°±ç»“æŸå½“å‰åœºæ™¯
            if (len(current_scene) >= min_length or 
                self.is_dialogue_heavy(paragraph) or
                self.is_action_scene(paragraph)):
                merged.append(current_scene.strip())
                current_scene = ""
        
        # å¤„ç†æœ€åä¸€ä¸ªåœºæ™¯
        if current_scene.strip():
            if merged:
                merged[-1] += "\n\n" + current_scene.strip()
            else:
                merged.append(current_scene.strip())
        
        return merged
    
    def generate_scene_title(self, content: str, scene_num: int) -> str:
        """ç”Ÿæˆåœºæ™¯æ ‡é¢˜"""
        # æå–å†…å®¹çš„å…³é”®è¯ä½œä¸ºæ ‡é¢˜
        first_sentence = content.split('ã€‚')[0][:50]
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        title = re.sub(r'["\n\r\t]', '', first_sentence)
        
        if not title:
            title = f"åœºæ™¯{scene_num}"
        
        return title
    
    def determine_scene_type(self, content: str) -> str:
        """åˆ¤æ–­åœºæ™¯ç±»å‹"""
        if 'ã€' in content and 'ã€‘' in content:
            return "TUTORIAL"
        elif '"' in content or '"' in content:
            return "DIALOGUE"
        elif any(word in content for word in ['æˆ˜æ–—', 'æ”»å‡»', 'è¡€', 'æ­»äº¡']):
            return "COMBAT"
        else:
            return "NORMAL"
    
    def is_ending_scene(self, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç»“å±€åœºæ™¯"""
        ending_keywords = ['ç»“æŸ', 'å®Œç»“', 'ç»ˆç« ', 'æ­»äº¡', 'æ¸¸æˆç»“æŸ']
        return any(keyword in content for keyword in ending_keywords)
    
    def is_dialogue_heavy(self, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¯¹è¯å¯†é›†åœºæ™¯"""
        dialogue_count = content.count('"') + content.count('"')
        return dialogue_count >= 4
    
    def is_action_scene(self, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŠ¨ä½œåœºæ™¯"""
        action_keywords = ['çªç„¶', 'ç«‹å³', 'è¿…é€Ÿ', 'å†²å‘', 'æŠ“ä½', 'è·‘', 'é€ƒ']
        return any(keyword in content for keyword in action_keywords)
    
    def generate_choices(self, scenes: List[Dict]) -> List[Dict]:
        """ä¸ºåœºæ™¯ç”Ÿæˆé€‰æ‹©åˆ†æ”¯"""
        choices = []
        
        for i, scene in enumerate(scenes):
            scene_choices = []
            
            # ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆ2-3ä¸ªé€‰æ‹©
            if i < len(scenes) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªåœºæ™¯
                # ä¸»è¦é€‰æ‹©ï¼šç»§ç»­å‰§æƒ…
                main_choice = {
                    'text': 'ç»§ç»­',
                    'next_scene': i + 2,  # ä¸‹ä¸€ä¸ªåœºæ™¯
                    'experience_reward': 10
                }
                scene_choices.append(main_choice)
                
                # å¯é€‰é€‰æ‹©ï¼šæ¢ç´¢æˆ–å…¶ä»–è¡ŒåŠ¨
                if scene['type'] == 'NORMAL':
                    alt_choice = {
                        'text': 'ä»”ç»†è§‚å¯Ÿå‘¨å›´',
                        'next_scene': i + 2,
                        'experience_reward': 15
                    }
                    scene_choices.append(alt_choice)
            
            choices.append({
                'scene_id': scene['scene_id'],
                'choices': scene_choices
            })
        
        return choices
    
    def export_to_json(self, output_file: str):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        data = {
            'chapters': self.chapters,
            'metadata': {
                'total_chapters': len(self.chapters),
                'total_scenes': sum(len(scenes) for scenes in self.chapters.values()),
                'processed_at': str(Path().cwd())
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")
    
    def export_to_java_data(self, output_file: str):
        """å¯¼å‡ºä¸ºJavaæ•°æ®æ ¼å¼"""
        java_code = []
        java_code.append("// è‡ªåŠ¨ç”Ÿæˆçš„æ•…äº‹æ•°æ®")
        java_code.append("private void loadProcessedStories() {")
        
        for chapter_num, scenes in self.chapters.items():
            for scene in scenes:
                java_code.append(f"    createStoryFromData({chapter_num}, {scene['scene_id']}, ")
                java_code.append(f"        \"{scene['title']}\",")
                java_code.append(f"        \"{scene['content']}\",")
                java_code.append(f"        \"{scene['type']}\", {str(scene['is_ending']).lower()});")
                java_code.append("")
        
        java_code.append("}")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(java_code))
        
        print(f"âœ… Javaä»£ç å·²å¯¼å‡ºåˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    processor = NovelTextProcessor()
    
    # å¤„ç†åŸå§‹æ–‡æœ¬ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    raw_text_file = "../raw_novel.txt"
    if Path(raw_text_file).exists():
        processor.process_raw_text(raw_text_file)
        
        # å¯¼å‡ºç»“æœ
        processor.export_to_json("../processed_novel.json")
        processor.export_to_java_data("../generated_stories.java")
    else:
        print(f"âŒ åŸå§‹æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {raw_text_file}")
        print("ğŸ’¡ è¯·å°†å°è¯´æ–‡æœ¬ä¿å­˜ä¸º raw_novel.txt")

if __name__ == "__main__":
    main()
