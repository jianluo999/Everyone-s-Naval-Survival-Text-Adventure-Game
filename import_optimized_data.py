#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¼å…¥ä¼˜åŒ–åçš„åœºæ™¯å’Œé€‰æ‹©æ•°æ®
"""

import json
import pymysql
from typing import List, Dict

class OptimizedDataImporter:
    def __init__(self):
        self.db_config = {
            'host': 'localhost',
            'user': 'root',
            'password': 'mgsincos30',
            'database': 'sailing_game',
            'charset': 'utf8mb4'
        }

    def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        return pymysql.connect(**self.db_config)

    def clear_existing_data(self):
        """æ¸…ç©ºç°æœ‰æ•°æ®"""
        print("ğŸ—‘ï¸ æ¸…ç©ºç°æœ‰æ•°æ®...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # æ¸…ç©ºé€‰æ‹©è¡¨
            cursor.execute("DELETE FROM choices WHERE story_id LIKE 'story_%'")
            print(f"âœ… æ¸…ç©ºé€‰æ‹©æ•°æ®: {cursor.rowcount} æ¡")
            
            # æ¸…ç©ºåœºæ™¯è¡¨
            cursor.execute("DELETE FROM stories WHERE story_id LIKE 'story_%'")
            print(f"âœ… æ¸…ç©ºåœºæ™¯æ•°æ®: {cursor.rowcount} æ¡")
            
            conn.commit()
            
        except Exception as e:
            print(f"âŒ æ¸…ç©ºæ•°æ®å¤±è´¥: {e}")
            conn.rollback()
        finally:
            cursor.close()
            conn.close()

    def import_scenes_batch(self, scenes: List[Dict], batch_size: int = 500):
        """æ‰¹é‡å¯¼å…¥åœºæ™¯æ•°æ®"""
        print(f"ğŸ“– å¼€å§‹å¯¼å…¥ {len(scenes)} ä¸ªä¼˜åŒ–åœºæ™¯...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        insert_sql = """
        INSERT INTO stories (story_id, title, content, chapter, scene, story_type, is_ending)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        """
        
        try:
            total_batches = (len(scenes) + batch_size - 1) // batch_size
            
            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min(start_idx + batch_size, len(scenes))
                batch_scenes = scenes[start_idx:end_idx]
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_data = []
                for scene in batch_scenes:
                    batch_data.append((
                        scene['story_id'],
                        scene['title'],
                        scene['content'],
                        scene['chapter'],
                        scene['scene'],
                        scene['story_type'],
                        scene['is_ending']
                    ))
                
                # æ‰§è¡Œæ‰¹é‡æ’å…¥
                cursor.executemany(insert_sql, batch_data)
                conn.commit()
                
                print(f"âœ… åœºæ™¯æ‰¹æ¬¡ {batch_num + 1}/{total_batches}: {len(batch_data)} ä¸ªåœºæ™¯")
            
            print(f"ğŸ‰ åœºæ™¯å¯¼å…¥å®Œæˆ: {len(scenes)} ä¸ª")
            
        except Exception as e:
            print(f"âŒ åœºæ™¯å¯¼å…¥å¤±è´¥: {e}")
            conn.rollback()
        finally:
            cursor.close()
            conn.close()

    def import_choices_batch(self, choices: List[Dict], batch_size: int = 500):
        """æ‰¹é‡å¯¼å…¥é€‰æ‹©æ•°æ®"""
        print(f"ğŸ¯ å¼€å§‹å¯¼å…¥ {len(choices)} ä¸ªä¼˜åŒ–é€‰æ‹©...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        insert_sql = """
        INSERT INTO choices (story_id, text, next_story_id, requirements, is_available, 
                           health_cost, health_reward, gold_cost, gold_reward, experience_reward)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        try:
            total_batches = (len(choices) + batch_size - 1) // batch_size
            
            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min(start_idx + batch_size, len(choices))
                batch_choices = choices[start_idx:end_idx]
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_data = []
                for choice in batch_choices:
                    batch_data.append((
                        choice['story_id'],
                        choice['text'],
                        choice['next_story_id'],
                        choice['requirements'],
                        choice['is_available'],
                        choice['health_cost'],
                        choice['health_reward'],
                        choice['gold_cost'],
                        choice['gold_reward'],
                        choice['experience_reward']
                    ))
                
                # æ‰§è¡Œæ‰¹é‡æ’å…¥
                cursor.executemany(insert_sql, batch_data)
                conn.commit()
                
                print(f"âœ… é€‰æ‹©æ‰¹æ¬¡ {batch_num + 1}/{total_batches}: {len(batch_data)} ä¸ªé€‰æ‹©")
            
            print(f"ğŸ‰ é€‰æ‹©å¯¼å…¥å®Œæˆ: {len(choices)} ä¸ª")
            
        except Exception as e:
            print(f"âŒ é€‰æ‹©å¯¼å…¥å¤±è´¥: {e}")
            conn.rollback()
        finally:
            cursor.close()
            conn.close()

    def verify_import(self):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        print("ğŸ“Š éªŒè¯å¯¼å…¥ç»“æœ...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        try:
            # æ£€æŸ¥åœºæ™¯æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM stories WHERE story_id LIKE 'story_%'")
            scene_count = cursor.fetchone()[0]
            print(f"âœ… åœºæ™¯æ€»æ•°: {scene_count}")
            
            # æ£€æŸ¥é€‰æ‹©æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM choices WHERE story_id LIKE 'story_%'")
            choice_count = cursor.fetchone()[0]
            print(f"âœ… é€‰æ‹©æ€»æ•°: {choice_count}")
            
            # æ£€æŸ¥ç« èŠ‚èŒƒå›´
            cursor.execute("SELECT MIN(chapter), MAX(chapter), COUNT(DISTINCT chapter) FROM stories WHERE story_id LIKE 'story_%'")
            min_ch, max_ch, total_ch = cursor.fetchone()
            print(f"âœ… ç« èŠ‚èŒƒå›´: ç¬¬{min_ch}ç«  - ç¬¬{max_ch}ç«  (å…±{total_ch}ç« )")
            
            # æ£€æŸ¥ä¼˜åŒ–æ•ˆæœ - ç¬¬ä¸€äººç§°è½¬æ¢
            cursor.execute("SELECT COUNT(*) FROM stories WHERE content LIKE '%æˆ‘%' AND story_id LIKE 'story_%'")
            first_person_count = cursor.fetchone()[0]
            print(f"âœ… ç¬¬ä¸€äººç§°åœºæ™¯: {first_person_count} ä¸ª")
            
            # æ£€æŸ¥æ™ºèƒ½æ ‡é¢˜
            cursor.execute("SELECT COUNT(*) FROM stories WHERE title LIKE '%ï¼š%' AND story_id LIKE 'story_%'")
            smart_title_count = cursor.fetchone()[0]
            print(f"âœ… æ™ºèƒ½æ ‡é¢˜åœºæ™¯: {smart_title_count} ä¸ª")
            
            # æ£€æŸ¥é€‰æ‹©å¤šæ ·æ€§
            cursor.execute("SELECT COUNT(DISTINCT text) FROM choices WHERE story_id LIKE 'story_%'")
            unique_choices = cursor.fetchone()[0]
            print(f"âœ… ç‹¬ç‰¹é€‰æ‹©ç±»å‹: {unique_choices} ç§")
            
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        finally:
            cursor.close()
            conn.close()

    def import_optimized_data(self, scenes_file: str, choices_file: str):
        """å¯¼å…¥ä¼˜åŒ–åçš„æ•°æ®"""
        print("ğŸš€ å¼€å§‹å¯¼å…¥ä¼˜åŒ–åçš„æ¸¸æˆæ•°æ®...")
        
        # åŠ è½½ä¼˜åŒ–åçš„æ•°æ®
        print("ğŸ“‚ åŠ è½½ä¼˜åŒ–æ•°æ®...")
        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes = json.load(f)
        
        with open(choices_file, 'r', encoding='utf-8') as f:
            choices = json.load(f)
        
        print(f"ğŸ“– åŠ è½½åœºæ™¯: {len(scenes)} ä¸ª")
        print(f"ğŸ¯ åŠ è½½é€‰æ‹©: {len(choices)} ä¸ª")
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        self.clear_existing_data()
        
        # å¯¼å…¥ä¼˜åŒ–åçš„æ•°æ®
        self.import_scenes_batch(scenes)
        self.import_choices_batch(choices)
        
        # éªŒè¯å¯¼å…¥ç»“æœ
        self.verify_import()
        
        print("ğŸ‰ ä¼˜åŒ–æ•°æ®å¯¼å…¥å®Œæˆï¼")

def main():
    importer = OptimizedDataImporter()
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    scenes_file = "novel_texts/optimized_scenes/optimized_scenes.json"
    choices_file = "novel_texts/optimized_scenes/optimized_choices.json"
    
    # æ‰§è¡Œå¯¼å…¥
    importer.import_optimized_data(scenes_file, choices_file)

if __name__ == "__main__":
    main()
